# Group Memebers:

## Eris Leksi
## Erica Holden
## Reham Abuarqoub

# Sustainable AI: Prompt Optimization & Probabilistic Language Modeling

## Project Overview

This project focuses on optimizing AI prompts to reduce their length and complexity while preserving semantic meaning, contributing to energy-efficient AI usage. Using probabilistic language models and NLP techniques, we analyze, preprocess, and rewrite prompts from a real-world corpus to reduce token counts and computational cost during inference.


## Features

- **Corpus Loading & Preprocessing**  
  Load a predefined corpus of prompts, clean text, tokenize, normalize, remove stopwords, and apply stemming.

- **Probabilistic Language Models**  
  Implement unigram and bigram models with Maximum Likelihood Estimation (MLE) to calculate word and sequence probabilities.

- **Prompt Rewriting Heuristics**  
  Apply simple rewriting rules to shorten prompts by removing filler phrases and simplifying wording.

- **Semantic Similarity Evaluation**  
  Use sentence-transformers to measure cosine similarity between original and rewritten prompts, ensuring meaning is preserved.
